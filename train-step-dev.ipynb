{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ebcf29-8fe2-4fea-9a32-3581e7bb684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import config_dataloader\n",
    "from llama import LLaMAConfig, LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676e491e-497e-49b9-81b4-6a332c193ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    bsz: int = 16\n",
    "    lr: float = 1e-4\n",
    "    n_steps: int = 1000\n",
    "    pad_token_id: int = 65535  # Max value of uint16\n",
    "\n",
    "cfg_t = TrainerConfig()\n",
    "cfg_m = LLaMAConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50982c1a-8cad-422c-9467-1bf56826c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = config_dataloader(cfg_t.bsz, cfg_m.seq_len, cfg_t.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b7bfc2-0d8b-418c-8c55-2ad4a696d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "data_iter = iter(load_data())\n",
    "inputs_, targets_ = next(data_iter)\n",
    "while mx.all(inputs_ != cfg_t.pad_token_id):\n",
    "    targets_ = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6c7905-d6da-4165-9ee4-e311c5e471f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLaMA(**asdict(cfg_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c76d2104-17b9-4fb9-9058-58495b351412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx import nn\n",
    "\n",
    "def forward(model, inputs, targets):\n",
    "    pad_mask = (inputs != cfg_t.pad_token_id)\n",
    "    logits = model(inputs * pad_mask)\n",
    "\n",
    "    logprobs = nn.losses.cross_entropy(logits, targets)\n",
    "    logprobs_m = logprobs * pad_mask\n",
    "    loss = logprobs_m.sum() / pad_mask.sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05599ceb-909b-411b-b2a5-7ea4870bb0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(10.5277, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_grad = nn.value_and_grad(model, forward)\n",
    "loss, grad = loss_and_grad(model, inputs_, targets_)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56f3377-81f2-4c6a-8477-27bed3eb1a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(61.2031, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "optimizer = optim.AdamW(learning_rate=cfg_t.lr)\n",
    "state = [model.state, optimizer.state]\n",
    "\n",
    "@partial(mx.compile, inputs=state, outputs=state)\n",
    "def train_step(inputs, targets):\n",
    "    loss_and_grad = nn.value_and_grad(model, forward)\n",
    "    loss, grads = loss_and_grad(model, inputs, targets)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "loss = train_step(inputs_, targets_)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69943cf-2466-42ec-ae74-80f41ff15238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(55.4943, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step(inputs_, targets_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
